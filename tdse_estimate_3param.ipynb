{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tdse_estimate_3param.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oH4b3aaGabxv",
        "ezGtu0OjwAjH",
        "QtMuCwjz0Jfo",
        "uA1b3eq4102K",
        "agpC1IRhHymQ",
        "mYnV03kq3Iu4",
        "d6f4FpWW37J2",
        "kLC4GdGEJ7Zb",
        "k3huTjKDc3M0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgyPCSMVT4dE"
      },
      "source": [
        "# M.Lytova, M.Spanner, I.Tamblyn. *Deep learning and high harmonic generation* (2020)\n",
        "## Codes for Section IV.B : *Estimating $\\lambda$-set values*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH4b3aaGabxv"
      },
      "source": [
        "##Headers and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTQE-2nzHKPj"
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, Dropout, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Reshape\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Nadam, Adam\n",
        "from tensorflow.keras import initializers\n",
        "from keras import objectives\n",
        "from keras.losses import mean_squared_error\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import backend as K\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r-mi7kh89JP"
      },
      "source": [
        "PI = 3.14159265359\n",
        "\n",
        "t_n_points = 4096   # number of nodes in time\n",
        "t_n = np.linspace(0, 800, t_n_points)/41.341    # grid in time, Tmax = 800 a.u. = 19.35 fs\n",
        "\n",
        "n_train = 30000   # training set size\n",
        "n_test = 1000     # testing set size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezGtu0OjwAjH"
      },
      "source": [
        "##Loading a training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhJPHsfMYcNf"
      },
      "source": [
        "param_train = np.zeros((n_train, 3))\n",
        "path2param = f\"/hhg_reduced/param.dat\"\n",
        "param_train = np.loadtxt(path2param, delimiter = \",\", max_rows = n_train) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etzDFbe8A0p9"
      },
      "source": [
        "y_train = np.zeros((n_train, t_n_points))\n",
        "path2load0 = f\"/hhg_reduced/hhg\"\n",
        "\n",
        "tic = time.perf_counter()\n",
        "\n",
        "for i in range(n_train): \n",
        "    path2load = path2load0 + str(i+1) + '.dat'    \n",
        "    load_data = np.loadtxt(path2load)\n",
        "    y_train[i] = load_data[0:t_n_points] * np.sin(PI*t_n/Tmax) \n",
        "    if (round(i/1000)==i/1000):\n",
        "        print(i)        \n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Training set preparation time {toc - tic:0.4f} seconds\")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOXyAC5-kkQC"
      },
      "source": [
        "def plot_train_example(i):\n",
        "    plt.figure(figsize=(16,5), constrained_layout=False)    \n",
        "    plt.plot(t_n, y_train[i], color='green')\n",
        "    plt.xlim(0, 20)\n",
        "    plt.xticks(np.arange(0, 20, 2.0))\n",
        "    plt.grid()\n",
        "    plt.show() \n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Je1zcTcy5kWw"
      },
      "source": [
        "### Drawing of a randomly chosen $d_k(t)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMqF9QZc6Z94"
      },
      "source": [
        "i_show = np.random.randint(0, n_train-1)\n",
        "print(\"theta = \", param_train[i_show,0]*180/PI, \", R = \", param_train[i_show,1], \"a.u., I = \", (param_train[i_show,2]/5.338027e-2)**2, \"e14 W/cm^2\")\n",
        "plot_train_example(i_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtMuCwjz0Jfo"
      },
      "source": [
        "##Loading a testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAJh4b3NbY63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9eb93a1-1246-49ff-863f-fcd989221518"
      },
      "source": [
        "param_test = np.zeros((n_test, 3))\n",
        "path2param = f\"/hhg_reduced/param.dat\"\n",
        "param_test = np.loadtxt(path2param, delimiter = \",\", skiprows = n_train, max_rows = n_test) \n",
        "\n",
        "print(\"Testing param set size: \", param_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing param set size:  (1000, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gbEt-EtcEUp"
      },
      "source": [
        "y_test = np.zeros((n_test, t_n_points))\n",
        "path2load0 = f\"/hhg_reduced/hhg\"\n",
        "\n",
        "for i in range(n_test): \n",
        "    path2load = path2load0 + str(i+1+n_train) + '.dat'    \n",
        "    load_data = np.loadtxt(path2load)\n",
        "    y_test[i] = load_data[0:t_n_points] * np.sin(PI*t_n/Tmax)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA1b3eq4102K"
      },
      "source": [
        "##Normalizing before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3qAooRD14WC"
      },
      "source": [
        "max_E0 = np.amax(param_train[:,2])\n",
        "min_E0 = np.amin(param_train[:,2])\n",
        "param_train_norm = (param_train-[0, 1.5, min_E0])/[PI/2, 2.5, (max_E0-min_E0)]\n",
        "param_test_norm = (param_test-[0, 1.5, min_E0])/[PI/2, 2.5, (max_E0-min_E0)]\n",
        "y_max = 0.3\n",
        "y_train_norm = y_train/y_max\n",
        "y_test_norm = y_test/y_max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agpC1IRhHymQ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3soogDl9x7Hu"
      },
      "source": [
        "inputs = Input(shape=(t_n_points,))\n",
        "\n",
        "x = Dense(512, activation='softplus')(inputs)\n",
        "x = Reshape((512, 1))(x) \n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x)\n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x) \n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x) \n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x) \n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x)\n",
        "x = MaxPooling1D(2, padding='same')(x)\n",
        "x = Conv1D(8, 4, activation='softplus', padding='same')(x) \n",
        "x = Conv1D(1, 4, activation='softplus', padding='same')(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(64, activation='softplus')(x)\n",
        "x = Dense(16, activation='softplus')(x)\n",
        "outputs = Dense(3, activation='softplus')(x)\n",
        "\n",
        "ModelLambda = Model(inputs, outputs)\n",
        "opt = Adam(lr=0.0005, amsgrad=True)\n",
        "ModelLambda.compile(optimizer=opt, loss='mean_squared_error') \n",
        "\n",
        "print(ModelLambda.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnV03kq3Iu4"
      },
      "source": [
        "##Training\n",
        "\n",
        "*   Training set: 30,000\n",
        "*   Testing set: 1,000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-YmxUb-zw-O"
      },
      "source": [
        "def plot_losses2():\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(np.log10(loss_sum),color='blue')\n",
        "    plt.plot(np.log10(val_loss_sum),color='red')\n",
        "    plt.ylabel('log(Loss)', fontsize=12)\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.legend(['training', 'validation'], loc='upper right', fontsize=14)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1_3aee3Kwi"
      },
      "source": [
        "tic = time.perf_counter()\n",
        "\n",
        "for n in range(3, 10):           # training in a cycle with increasing batch size\n",
        "\n",
        "      batch_size = 2**n     \n",
        "\n",
        "      history = ModelLambda.fit(y_train_norm, param_train_norm, \n",
        "                             epochs=100,\n",
        "                             batch_size=batch_size,\n",
        "                             shuffle=True,\n",
        "                             validation_data=(y_test_norm, param_test_norm))\n",
        "      \n",
        "      path = f\"/estimate_thetaRI/model_1\" \n",
        "      ModelLambda.save(path) \n",
        "\n",
        "      loss_save = history.history['loss']\n",
        "      val_loss_save = history.history['val_loss']\n",
        "      if n > 3:\n",
        "            loss_sum = np.concatenate((loss_sum, loss_save), axis = 0)\n",
        "            val_loss_sum = np.concatenate((val_loss_sum, val_loss_save), axis = 0)\n",
        "      else:\n",
        "            loss_sum = loss_save\n",
        "            val_loss_sum = val_loss_save            \n",
        "      \n",
        "      plot_losses2()\n",
        "\n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Execution time {toc - tic:0.4f} seconds\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6f4FpWW37J2"
      },
      "source": [
        "##Training and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMz7BYc8gIeE"
      },
      "source": [
        "plot_losses2()  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLC4GdGEJ7Zb"
      },
      "source": [
        "##Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrDGLoQRJ6yf"
      },
      "source": [
        "prediction_norm = ModelLambda.predict(y_test_norm)\n",
        "prediction = prediction_norm * [PI/2, 2.5, (max_E0-min_E0)] + [0, 1.5, min_E0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3huTjKDc3M0"
      },
      "source": [
        "##Predicted vs True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90l59jAvkyuz"
      },
      "source": [
        "def plot_predict_true2():\n",
        "    fig = plt.subplots(3,1,figsize=(4,12),constrained_layout=False)\n",
        "    plt.subplot(311)\n",
        "    plt.scatter(param_test[:,0]*180/PI, prediction[:,0]*180/PI, color=\"blue\", s = 0.5)\n",
        "    plt.ylabel('Predicted', fontsize=14)\n",
        "    plt.xlim(0,90)\n",
        "    plt.ylim(0,90)\n",
        "    plt.xticks(np.arange(0, 91, 30))\n",
        "    plt.yticks(np.arange(0, 91, 30))\n",
        "    plt.grid()\n",
        "    plt.subplot(312)\n",
        "    plt.scatter(param_test[:,1], prediction[:,1], color=\"red\", s = 0.5)\n",
        "    plt.ylabel('Predicted', fontsize=14)\n",
        "    plt.xlim(1.5,4)\n",
        "    plt.ylim(1.5,4)\n",
        "    plt.xticks(np.arange(1.5, 4.1, 0.5))\n",
        "    plt.yticks(np.arange(1.5, 4.1, 0.5))\n",
        "    plt.grid()\n",
        "    plt.subplot(313)\n",
        "    (param_test[i,2]/5.338027e-2)**2\n",
        "    plt.scatter((param_test[:,2]/5.338027e-2)**2, (prediction[:,2]/5.338027e-2)**2, color=\"green\", s = 0.5)\n",
        "    plt.ylabel('Predicted', fontsize=14)\n",
        "    plt.xlabel('True', fontsize=14)\n",
        "    plt.xlim(1,4)\n",
        "    plt.ylim(1,4)\n",
        "    plt.xticks(np.arange(1, 4.1, 1))\n",
        "    plt.yticks(np.arange(1, 4.1, 1))\n",
        "    plt.grid()  \n",
        "    plt.show() \n",
        "    plt.close()\n",
        "\n",
        "plot_predict_true2()    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
