{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sine_autoencoder.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oH4b3aaGabxv",
        "A00TL11RyHRk",
        "AGeoqHWjyLVp",
        "4DU7lcqDzMPs",
        "l_MPH6j5uGmW",
        "D6h_P5389Gx0",
        "mseUR256Nj9p",
        "oyxbyrn70IVM",
        "ZCD_pvBqBQh6",
        "5jTmm_pGYK82"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgyPCSMVT4dE"
      },
      "source": [
        "#M.Lytova, M.Spanner, I.Tamblyn. Deep learning and high harmonic generation (2020)\n",
        "##Codes for Section II.D : Autoencoders and latent space visualization \n",
        "###see also (for beta=1) https://github.com/emnajaoua/beta_variational_autoencoders/blob/master/disentangled_vae%20(1).ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH4b3aaGabxv"
      },
      "source": [
        "##Headers and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTQE-2nzHKPj"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense, Dropout, Lambda\n",
        "from keras import backend as K\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam, Nadam\n",
        "from keras import objectives\n",
        "from keras.losses import mean_squared_error\n",
        "from keras.callbacks import TensorBoard\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r-mi7kh89JP"
      },
      "source": [
        "PI = 3.14159265359\n",
        "\n",
        "x_n_points = 512   # number of nodes in input layer\n",
        "x_n = np.linspace(0, 100, x_n_points) \n",
        "\n",
        "# VAE parameters\n",
        "batch_size = 128\n",
        "original_dim = x_n_points\n",
        "input_shape = (original_dim, )\n",
        "intermediate_dim1 = 128\n",
        "intermediate_dim2 = 64\n",
        "intermediate_dim3 = 16\n",
        "latent_dim = 2\n",
        "epsilon_std = 1\n",
        "\n",
        "n_train = batch_size * 4000   \n",
        "n_test = batch_size *1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A00TL11RyHRk"
      },
      "source": [
        "##Training set generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wkJQMcUT8wY"
      },
      "source": [
        "# Training set\n",
        "all2_train = np.random.rand(n_train,2)\n",
        "w0_train = all2_train[:,0]*0.5+0.5    # vector of random frequencies in [0.5, 1]\n",
        "A0_train = all2_train[:,1]*0.5+0.5    # vector of random amplitudes in [0.5, 1]\n",
        "\n",
        "y_train = np.zeros((n_train, x_n_points))\n",
        "for i in range(n_train):\n",
        "    y_train[i,] = A0_train[i] * (np.sin(w0_train[i]*x_n))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGeoqHWjyLVp"
      },
      "source": [
        "##Testing set generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etzDFbe8A0p9"
      },
      "source": [
        "# Testing set\n",
        "all2_test = np.random.rand(n_test,2)\n",
        "w0_test = all2_test[:,0]*0.5+0.5   # vector of random frequencies in [0.5, 1]\n",
        "A0_test = all2_test[:,1]*0.5+0.5    # vector of random amplitudes in [0.5, 1]\n",
        "\n",
        "y_test = np.zeros((n_test, x_n_points))\n",
        "for i in range(n_test):\n",
        "    y_test[i,] = A0_test[i] * (np.sin(w0_test[i]*x_n))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DU7lcqDzMPs"
      },
      "source": [
        "##Latent space vectors, encoder and decoder\n",
        "512 $->$ 128 $->$ 64 $->$ 16 $->$ 2$->$ 16 $->$ 64 $->$ 128 $->$ 512"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yozTyxb_EbvW"
      },
      "source": [
        "#Generate the latent representation vectors \n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim),\n",
        "                              mean=0., stddev=epsilon_std)\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN1W8yexDco_"
      },
      "source": [
        "# Encoder\n",
        "\n",
        "inputs = Input(shape = input_shape, name='encoder_input')\n",
        "\n",
        "x = Dense(intermediate_dim1, activation='tanh')(inputs)\n",
        "x = Dense(intermediate_dim2, activation='tanh')(x)\n",
        "x = Dense(intermediate_dim3, activation='tanh')(x)\n",
        "\n",
        "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
        "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
        "\n",
        "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
        "\n",
        "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "\n",
        "print(encoder.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvSKKmMeqL9F"
      },
      "source": [
        "# Decoder\n",
        "\n",
        "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
        "\n",
        "x = Dense(intermediate_dim3, activation='tanh')(latent_inputs)\n",
        "x = Dense(intermediate_dim2, activation='tanh')(x)\n",
        "x = Dense(intermediate_dim1, activation='tanh')(x)\n",
        "\n",
        "outputs = Dense(original_dim, activation='tanh')(x)\n",
        "\n",
        "decoder = Model(latent_inputs, outputs, name='decoder')\n",
        "\n",
        "print(decoder.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QLyTpHqGB-x"
      },
      "source": [
        "outputs = decoder(encoder(inputs)[2]) \n",
        "\n",
        "vae = Model(inputs, outputs, name='vae_mlp')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7L5ZgkWINcg"
      },
      "source": [
        "reconstruction_loss = mean_squared_error(inputs, outputs)\n",
        "\n",
        "reconstruction_loss *= original_dim\n",
        "\n",
        "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
        "\n",
        "kl_loss = K.sum(kl_loss, axis=-1)\n",
        "\n",
        "kl_loss *= -0.5\n",
        "\n",
        "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
        "\n",
        "vae.add_loss(vae_loss)\n",
        "\n",
        "opt = Nadam(lr=0.0001)\n",
        "vae.compile(optimizer=opt)\n",
        "\n",
        "print(vae.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_MPH6j5uGmW"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ucRHlxKfnpl"
      },
      "source": [
        "tic = time.perf_counter()\n",
        "\n",
        "history = vae.fit(y_train, \n",
        "                epochs=150,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=True,\n",
        "                validation_data=(y_test, None))\n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Execution time {toc - tic:0.4f} seconds\")\n",
        "\n",
        "def plot_losses():\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(np.log10(history.history['loss']),color='blue')\n",
        "    plt.plot(np.log10(history.history['val_loss']),color='red')\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper right')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6h_P5389Gx0"
      },
      "source": [
        "##Training and validation losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXO0_QBChWRl"
      },
      "source": [
        "plot_losses()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mseUR256Nj9p"
      },
      "source": [
        "##Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qefvJSL6NA8f"
      },
      "source": [
        "z_mean, _, _ = encoder.predict(y_test, batch_size=batch_size)\n",
        "decoded_sin = decoder.predict(z_mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyxbyrn70IVM"
      },
      "source": [
        "## Drawing the latent space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6ReucRVlRYT"
      },
      "source": [
        "def plot_latent(z0, z1):\n",
        "    fig1 = plt.subplots(1,2,figsize=(12,4), constrained_layout=False)\n",
        "    plt.suptitle ('Colorbar wrt $w_0$', fontsize=16)\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(z0, z1, c = w0_test, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$z_0$', fontsize=14)\n",
        "    plt.ylabel('$z_1$', fontsize=14)\n",
        "    plt.title('In Cartesian coordinates', fontsize=14)\n",
        "    plt.subplot(122)\n",
        "    plt.scatter(np.sqrt(z0**2+z1**2), np.arctan2(z1, z0), c = w0_test, cmap='jet')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$r$', fontsize=14)\n",
        "    plt.ylabel(r'$\\theta$', fontsize=14)\n",
        "    plt.title('In polar coordinates', fontsize=14)\n",
        "\n",
        "    fig2 = plt.subplots(1,2,figsize=(12,4), constrained_layout=False)\n",
        "    plt.suptitle ('Colorbar wrt $A_0$', fontsize=16)\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(z0, z1, c = A0_test, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$z_0$', fontsize=14)\n",
        "    plt.ylabel('$z_1$', fontsize=14)\n",
        "    plt.title('In Cartesian coordinates$', fontsize=14)\n",
        "    plt.subplot(122)\n",
        "    plt.scatter(np.sqrt(z0**2+z1**2), np.arctan2(z1, z0), c = A0_test, cmap='viridis')\n",
        "    plt.colorbar()\n",
        "    plt.xlabel('$r$', fontsize=14)\n",
        "    plt.ylabel(r'$\\theta$', fontsize=14)\n",
        "    plt.title('In polar coordinates', fontsize=14)\n",
        "    plt.show()  \n",
        "    plt.close()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3VxLL6cHYYn"
      },
      "source": [
        "plot_latent(z_mean[:, 0], z_mean[:,1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCD_pvBqBQh6"
      },
      "source": [
        "##Function to draw the test and reconstructed examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DqRpYJBBTQS"
      },
      "source": [
        "def plot_examples(i1, i2):    \n",
        "    fig = plt.subplots(2,1,figsize=(12,8),constrained_layout=False)\n",
        "    plt.suptitle('Examples: Test points and prediction', fontsize=16)\n",
        "    plt.subplot(211)\n",
        "    plt.title('w0 = ' + str(round(w0_test[i1],2)) + \",  A = \" + str(round(A0_test[i1],2)), fontsize=16)\n",
        "    plt.scatter(x_n, y_test[i1], color=\"blue\", s = 1)\n",
        "    plt.plot(x_n, decoded_sin[i1], color=\"red\", linewidth = 1)\n",
        "    plt.grid()\n",
        "    plt.subplot(212)\n",
        "    plt.title('w0 = ' + str(round(w0_test[i2],2)) + \",  A = \" + str(round(A0_test[i2],2)), fontsize=16)\n",
        "    plt.scatter(x_n, y_test[i2], color=\"blue\", s = 1)\n",
        "    plt.plot(x_n, decoded_sin[i2], color=\"red\", linewidth = 1)  \n",
        "    plt.xlabel('$t$, fs', fontsize=16)\n",
        "    plt.grid()  \n",
        "    plt.show() \n",
        "    plt.close()        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jTmm_pGYK82"
      },
      "source": [
        "## Comparison of arbitrary $y_{test}$ (blue) and $y_{reconstructed}$ (red)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jhJG-EeOf2c"
      },
      "source": [
        "i_show1 = np.random.randint(0, n_test-1)\n",
        "i_show2 = np.random.randint(0, n_test-1)\n",
        "\n",
        "plot_examples(i_show1, i_show2)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}