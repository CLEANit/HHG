{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification_5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oH4b3aaGabxv",
        "ezGtu0OjwAjH",
        "QtMuCwjz0Jfo",
        "uA1b3eq4102K",
        "agpC1IRhHymQ",
        "mYnV03kq3Iu4",
        "kLC4GdGEJ7Zb",
        "m64VL92G4kby",
        "k3huTjKDc3M0"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgyPCSMVT4dE"
      },
      "source": [
        "# M.Lytova, M.Spanner, I.Tamblyn. *Deep learning and high harmonic generation* (2020)\n",
        "## Codes for Section IV.D : *Distinguishing diatomic and triatomic molecules by the dipole moment*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oH4b3aaGabxv"
      },
      "source": [
        "##Headers and constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTQE-2nzHKPj"
      },
      "source": [
        "from google.colab import files\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from tensorflow.keras import initializers\n",
        "from keras import objectives\n",
        "from keras.losses import binary_crossentropy, sparse_categorical_crossentropy\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras import backend as K\n",
        "import argparse\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2r-mi7kh89JP"
      },
      "source": [
        "PI = 3.14159265359\n",
        "\n",
        "t_n_points = 4096   # number of nodes in time\n",
        "t_n = np.linspace(0, 800, t_n_points)/41.341   # grid in time, Tmax = 800 a.u. = 19.35 fs\n",
        "\n",
        "n_train = 5000  # training set size - 1000 for each species\n",
        "n_test = 500    # testing set size - 100 for each species"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezGtu0OjwAjH"
      },
      "source": [
        "##Loading a training set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etzDFbe8A0p9"
      },
      "source": [
        "y_train = np.zeros((n_train, t_n_points))\n",
        "label_train = np.empty(n_train, dtype = 'i')\n",
        "path2load_di0 = f\"/hhg_reduced/hhg\"     \n",
        "path2load_diA0 = f\"/hhg_di_red/hhg\"\n",
        "path2load_tri0 = f\"/hhg_tri_red/hhg\"\n",
        "path2load_tri10 = f\"/hhg_tri_isos_red/hhg\"\n",
        "path2load_tri20 = f\"/hhg_tri_vers_red/hhg\"\n",
        "\n",
        "tic = time.perf_counter()\n",
        "\n",
        "for i in range(int(n_train/5)): \n",
        "    label_train[i] = 0                              # same labels as in the paper\n",
        "    label_train[int(n_train/5)+i] = 1\n",
        "    label_train[int(2*n_train/5)+i] = 2\n",
        "    label_train[int(3*n_train/5)+i] = 3\n",
        "    label_train[int(4*n_train/5)+i] = 4\n",
        "    path2load_di = path2load_di0 + str(i+1) + '.dat'\n",
        "    path2load_diA = path2load_diA0 + str(i+1) + '.dat'\n",
        "    path2load_tri = path2load_tri0 + str(i+1) + '.dat' \n",
        "    path2load_tri1 = path2load_tri10 + str(i+1) + '.dat' \n",
        "    path2load_tri2 = path2load_tri20 + str(i+1) + '.dat'    \n",
        "    load_data_di = np.loadtxt(path2load_di)\n",
        "    load_data_diA = np.loadtxt(path2load_diA)\n",
        "    load_data_tri = np.loadtxt(path2load_tri)\n",
        "    load_data_tri1 = np.loadtxt(path2load_tri1)\n",
        "    load_data_tri2 = np.loadtxt(path2load_tri2)\n",
        "    y_train[i] = load_data_di[0:t_n_points] * np.sin(PI*t_n/Tmax) \n",
        "    y_train[int(n_train/5)+i] = load_data_diA[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    y_train[int(2*n_train/5)+i] = load_data_tri[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    y_train[int(3*n_train/5)+i] = load_data_tri1[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    y_train[int(4*n_train/5)+i] = load_data_tri2[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    if (round(i/100)==i/100):\n",
        "        print(i)        \n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Training set preparation time {toc - tic:0.4f} seconds\")   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJXdG-BnVjUJ"
      },
      "source": [
        "def plot_train_example(i):\n",
        "    plt.figure(figsize=(12,4), constrained_layout=False)    \n",
        "    plt.plot(t_n, y_train[i], color='green')\n",
        "    plt.xlabel('$t, fs$', fontsize=14)\n",
        "    plt.ylabel('$y(t)$', fontsize=14)\n",
        "    plt.xticks(np.arange(0, Tmax, 2.0))\n",
        "    plt.grid()    \n",
        "    plt.show() \n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFCwEsxCILDZ"
      },
      "source": [
        "### Drawing of a randomly chosen $d_k(t)$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1JYBzPLWWUP"
      },
      "source": [
        "i_show = np.random.randint(0, n_train-1)\n",
        "plot_train_example(i_show)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtMuCwjz0Jfo"
      },
      "source": [
        "##Loading a testing set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gbEt-EtcEUp"
      },
      "source": [
        "y_test = np.zeros((n_test, t_n_points))\n",
        "label_test = np.empty(n_test, dtype = 'i')\n",
        "path2load_di0 = f\"/hhg_reduced/hhg\"\n",
        "path2load_diA0 = f\"/hhg_di_red/hhg\"\n",
        "path2load_tri0 = f\"/hhg_tri_red/hhg\"\n",
        "path2load_tri10 = f\"/hhg_tri_isos_red/hhg\"\n",
        "path2load_tri20 = f\"/hhg_tri_vers_red/hhg\"\n",
        "\n",
        "for i in range(int(n_test/5)): \n",
        "    label_test[i] = 0                     # same labels as in the paper\n",
        "    label_test[int(n_test/5)+i] = 1\n",
        "    label_test[int(2*n_test/5)+i] = 2\n",
        "    label_test[int(3*n_test/5)+i] = 3\n",
        "    label_test[int(4*n_test/5)+i] = 4\n",
        "    path2load_di = path2load_di0 + str(i+1+int(n_train/5)) + '.dat'\n",
        "    path2load_diA = path2load_diA0 + str(i+1+int(n_train/5)) + '.dat'\n",
        "    path2load_tri = path2load_tri0 + str(i+1+int(n_train/5)) + '.dat'\n",
        "    path2load_tri1 = path2load_tri10 + str(i+1+int(n_train/5)) + '.dat'\n",
        "    path2load_tri2 = path2load_tri20 + str(i+1+int(n_train/5)) + '.dat'    \n",
        "    load_data_di = np.loadtxt(path2load_di)\n",
        "    load_data_diA = np.loadtxt(path2load_diA)\n",
        "    load_data_tri = np.loadtxt(path2load_tri)\n",
        "    load_data_tri1 = np.loadtxt(path2load_tri1)\n",
        "    load_data_tri2 = np.loadtxt(path2load_tri2)\n",
        "    y_test[i] = load_data_di[0:t_n_points] * np.sin(PI*t_n/Tmax) \n",
        "    y_test[int(n_test/5)+i] = load_data_diA[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    y_test[int(2*n_test/5)+i] = load_data_tri[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    y_test[int(3*n_test/5)+i] = load_data_tri1[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    y_test[int(4*n_test/5)+i] = load_data_tri2[0:t_n_points] * np.sin(PI*t_n/Tmax)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uA1b3eq4102K"
      },
      "source": [
        "##Normalizing before training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3qAooRD14WC"
      },
      "source": [
        "y_max = 0.3\n",
        "y_train_norm = y_train/y_max\n",
        "y_test_norm = y_test/y_max"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agpC1IRhHymQ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3soogDl9x7Hu"
      },
      "source": [
        "inputs = Input(shape=(t_n_points,))\n",
        "\n",
        "x = Dense(128, activation='relu')(inputs)  \n",
        "x = Dense(64, activation='relu')(x)\n",
        "x = Dense(16, activation='relu')(x)\n",
        "outputs = Dense(5)(x)\n",
        "\n",
        "ModelClass = Model(inputs, outputs)\n",
        "opt = Adam(lr=0.001, amsgrad=True)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "ModelClass.compile(optimizer=opt, loss=loss, metrics=['accuracy']) \n",
        "\n",
        "print(ModelClass.summary())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYnV03kq3Iu4"
      },
      "source": [
        "##Training\n",
        "\n",
        "*   Training set: 5,000\n",
        "*   Testing set: 500"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-YmxUb-zw-O"
      },
      "source": [
        "def plot_losses2():\n",
        "    fig = plt.subplots(1,2,figsize=(12,5),constrained_layout=False)\n",
        "    plt.subplot(121)\n",
        "    plt.plot(np.log10(loss),color='blue')\n",
        "    plt.ylabel('log(Loss)', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=16)\n",
        "    plt.grid()\n",
        "    plt.subplot(122)\n",
        "    plt.plot(accur,color='red')\n",
        "    plt.ylabel('Accuracy', fontsize=16)\n",
        "    plt.xlabel('Epoch', fontsize=16)\n",
        "    plt.ylim(0.4, 1.0)\n",
        "    plt.grid()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wo1_3aee3Kwi"
      },
      "source": [
        "tic = time.perf_counter()\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "for n in range(1, 5):  # in a loop - to see the results every 500 epochs\n",
        "\n",
        "      history = ModelClass.fit(y_train_norm, label_train,                         \n",
        "                               epochs=500,\n",
        "                               batch_size=batch_size,\n",
        "                               shuffle=True,\n",
        "                               verbose=0)\n",
        "      \n",
        "      path = f\"/model_classify/model_1\" \n",
        "      ModelClass.save(path) \n",
        "\n",
        "      loss_save = history.history['loss']\n",
        "      accur_save = history.history['accuracy']\n",
        "\n",
        "      if n > 0:\n",
        "            loss = np.concatenate((loss, loss_save), axis = 0)\n",
        "            accur = np.concatenate((accur, accur_save), axis = 0)\n",
        "      else:\n",
        "            loss = loss_save\n",
        "            accur = accur_save\n",
        "\n",
        "      print(\"loss: \", loss[-1])\n",
        "      print(\"accuracy: \", accur[-1])\n",
        "      plot_losses2()\n",
        "\n",
        "\n",
        "toc = time.perf_counter()\n",
        "print(f\"Execution time {toc - tic:0.4f} seconds\")\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLC4GdGEJ7Zb"
      },
      "source": [
        "##Making a prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrDGLoQRJ6yf"
      },
      "source": [
        "probability_model = tf.keras.Sequential([ModelClass, tf.keras.layers.Softmax()])\n",
        "prediction = probability_model.predict(y_test_norm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0ETJ7JnBFpM"
      },
      "source": [
        "###Print a random example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpCO8FGGELwb"
      },
      "source": [
        "i_show = np.random.randint(0, n_test-1)\n",
        "print(i_show)\n",
        "print(prediction[i_show])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m64VL92G4kby"
      },
      "source": [
        "##Function that plots the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpYV5KxxBNZ5"
      },
      "source": [
        "def plot_histograms():\n",
        "  di_sym = np.zeros(5)\n",
        "  di_asym = np.zeros(5)\n",
        "  tri_sym = np.zeros(5)\n",
        "  tri1_asym = np.zeros(5)\n",
        "  tri2_asym = np.zeros(5)\n",
        "\n",
        "  for i in range(n_test):\n",
        "      true_label = label_test[i]\n",
        "      if true_label == 0:\n",
        "          di_sym += prediction[i]\n",
        "      elif true_label == 1:\n",
        "          di_asym += prediction[i]  \n",
        "      elif true_label == 2:\n",
        "          tri_sym += prediction[i]\n",
        "      elif true_label == 3:\n",
        "          tri1_asym += prediction[i]     \n",
        "      else :   \n",
        "          tri2_asym += prediction[i]\n",
        "\n",
        "  print(di_sym)          \n",
        "  print(di_asym)\n",
        "  print(tri_sym)\n",
        "  print(tri1_asym)\n",
        "  print(tri2_asym)\n",
        "\n",
        "\n",
        "  di_sym = di_sym/n_test*5.0\n",
        "  di_asym = di_asym/n_test*5.0\n",
        "  tri_sym = tri_sym/n_test*5.0\n",
        "  tri1_asym = tri1_asym/n_test*5.0\n",
        "  tri2_asym = tri2_asym/n_test*5.0\n",
        "\n",
        "  fig = plt.subplots(1,5,figsize=(20,4),constrained_layout=False)\n",
        "  plt.subplot(151)\n",
        "  plt.title(\"True label: 0\", fontsize=15)\n",
        "  plt.bar(range(5), di_sym, color=\"blue\", width=0.5)\n",
        "  plt.xticks(range(5), fontsize=12)\n",
        "  plt.yticks(np.arange(0, 1.2, 0.2), fontsize=12)\n",
        "  plt.ylim([0, 1.2])\n",
        "  plt.ylabel(\"Propability\", fontsize=15)\n",
        "  plt.subplot(152)\n",
        "  plt.title(\"True label: 1\", fontsize=15)\n",
        "  plt.bar(range(5), di_asym, color=\"red\", width=0.5)\n",
        "  plt.xticks(range(5), fontsize=12)\n",
        "  plt.yticks(np.arange(0, 1.2, 0.2), fontsize=12)\n",
        "  plt.ylim([0, 1.2])\n",
        "  plt.subplot(153)\n",
        "  plt.title(\"True label: 2\", fontsize=15)\n",
        "  plt.bar(range(5), tri_sym, color=\"green\", width=0.5)\n",
        "  plt.xticks(range(5), fontsize=12)\n",
        "  plt.yticks(np.arange(0, 1.2, 0.2), fontsize=12)\n",
        "  plt.ylim([0, 1.2])\n",
        "  plt.subplot(154)\n",
        "  plt.title(\"True label: 3\", fontsize=15)\n",
        "  plt.bar(range(5), tri1_asym, color=\"magenta\", width=0.5)\n",
        "  plt.xticks(range(5), fontsize=12)\n",
        "  plt.yticks(np.arange(0, 1.2, 0.2), fontsize=12)\n",
        "  plt.ylim([0, 1.2])\n",
        "  plt.subplot(155)\n",
        "  plt.title(\"True label: 4\", fontsize=15)\n",
        "  plt.bar(range(5), tri2_asym, color=\"cyan\", width=0.5)\n",
        "  plt.xticks(range(5), fontsize=12)\n",
        "  plt.yticks(np.arange(0, 1.2, 0.2), fontsize=12)\n",
        "  plt.ylim([0, 1.2])\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3huTjKDc3M0"
      },
      "source": [
        "##Predicted and True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0zZYA6WhwSO"
      },
      "source": [
        "plot_histograms() "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}